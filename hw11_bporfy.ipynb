{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw11_no_code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barnabasp/ML_Course/blob/main/hw11_bporfy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "315DLxAdHjPC"
      },
      "source": [
        "# HW 11.\n",
        "\n",
        "* Running the models may take minutes. This HW takes ~30 min to complete in computational time, so make sure you don't start it 1 hour before it is due.\n",
        "\n",
        "* Tasks 2-4. should be done using the `sklearn` library, the last is a pure TensorFlow ([Keras is part of TensorFlow](https://github.com/keras-team/keras/releases#:~:text=since%20this%20release-,Keras%202.2.,well%20as%20Theano%20and%20CNTK)) example.\n",
        "\n",
        "  * Never do `import keras` it only references `tf.keras` since version `2.4.0`!\n",
        "\n",
        "* The example notebook was run in Google COLAB without any package installation. I advise you to use Google COLAB with a GPU instance for the last task.\n",
        "\n",
        "## 1. Load the CIFAR 10 dataset from the `tf.keras.datasets` API and train a `LogisticRegression` model on the dataset and predict all test outcomes with the `sklearn` API\n",
        "\n",
        "* Create an image grid visualization of randomly selected images (9, 16) with labels.\n",
        "* Preprocess the dataset for `sklearn`, scale [0-1], and also flatten each example to a vector.\n",
        "* Use the `multi_class='multinomial'` option, describe what it means.\n",
        "* Plot the ROC curves and AUC scores on the same figure.\n",
        "* Calculate the accuracy of the classifier on the test set.\n",
        "\n",
        "* Make your life easier - time is precious - and run all the algorithms with multiprocessing.\n",
        "\n",
        "Hint:\n",
        "\n",
        "* `from sklearn.preprocessing import LabelBinarizer` might be useful for you.\n",
        "\n",
        "\n",
        "## 2. Train an `SGDClassifier` regression model on the dataset and predict all the test outcomes with the `sklearn` API. \n",
        "\n",
        "* Select the appropiate loss for this task, explain what this means.\n",
        "* Time is precious, run multiple jobs at the same time.\n",
        "* Plot the ROC curves and AUC scores on the same figure for the test set.\n",
        "* Calculate the accuracy of the classifier.\n",
        "* Why is this worse than the previous model?\n",
        "* Describe the above model with your own words, how is it different than the logistic regression model?\n",
        "\n",
        "## 3. Train a RandomForest classifier\n",
        "\n",
        "* Plot the ROC curve with AUC scores on the test set.\n",
        "* Calculate accuracy of the classifier on the test set.\n",
        "* Time is precious, run multiple jobs at the same time.\n",
        "\n",
        "## 4. Train an multi layer perceptron classifier\n",
        "\n",
        "* use the `MLPClassifier` from `sklearn`\n",
        "* Set its parameter to `max_iter = 30` or if you have time, set it for at least `100`. After `30` iterations the model does not converge but gives reasonable predictions (with default parameters).\n",
        "* Plot the ROC curves with AUC scores for the test set.\n",
        "* Calculate the accuracy of the model on the test set.\n",
        "\n",
        "## 5. Train a ResNet50 CNN model on the dataset, utilize pre-trained weights and fine-tune for at least 3 epochs:\n",
        "\n",
        "* training for 3 epochs should be enough to prove that this model is superior compared to others, train longer and you'll see exceptional results\n",
        "\n",
        "Convert the dataset:\n",
        "\n",
        "```python\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(32)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
        "test_dataset = test_dataset.batch(32)\n",
        "```\n",
        "\n",
        "Hints:\n",
        "\n",
        "* loading a pretrained model and letting its parameters be tunable\n",
        "\n",
        "```python\n",
        "backbone = tf.keras.applications.YOUR_MODEL_OF_CHOICE\n",
        "backbone.trainable = True # DO NOT FORGET TO UNFREEZE IT\n",
        "```\n",
        "\n",
        "* defining your custom model with the pretrained backbone\n",
        "\n",
        "```python\n",
        "# YOUR_MODEL_OF_CHOICE here is ResNet50 (!) as described in the task description.\n",
        "\n",
        "# Functional TensorFlow API\n",
        "def my_own_model():\n",
        "  input_placeholder = tf.keras.layers.Input(shape=(32, 32, 3))\n",
        "  # DO NOT FORGET THE PROPER INPUT PREPROCESSING FOR THE BACKBONE\n",
        "  x = tf.keras.applications.YOUR_MODEL_OF_CHOISE.preprocess_input(PROPER_INPUT)\n",
        "  # PLEASE USE THE PROPER INPUT: (e.g. 8 bit input)\n",
        "  x = backbone(x)\n",
        "  # Here comes some more layers\n",
        "  # and flattening at the end if needed!\n",
        "  out = # layer outputting the specified number of classes\n",
        "        # with or without a softmax activation, later on\n",
        "        # the choice of the loss depends on this\n",
        "  model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
        "  return model\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1eGXiD1HiYo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}