{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "bporfy_lab_10_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barnabasp/ML_Course/blob/main/bporfy_lab_10_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "8b7e51d8-f81e-4c5f-8a48-7159ead65e99"
      },
      "source": [
        "# 10. Convolutional neural networks\n",
        "\n",
        "In this assignment you'll use a photo-Z dataset acquired from the observations of the SDSS telescope located in New Mexico. The goal is to predict redshifts from multiband images of galaxies. As a warmup you'll work with the SVHN dataset.\n",
        "\n",
        "**<font color='red'>[WARN]:</font> For this assignment you'll need significantly more computational power compared to previous assignments! If you don't have a CUDA-capable GPU with >4Gb VRAM and >8Gb RAM, then you're advised to work on Google Colab!**"
      ],
      "id": "8b7e51d8-f81e-4c5f-8a48-7159ead65e99"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-yT-15voDBB"
      },
      "source": [
        "#!unzip /content/drive/MyDrive/Colab\\ Notebooks/10/archive.zip"
      ],
      "id": "e-yT-15voDBB",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnF_Wc8pol2c",
        "outputId": "65331f7a-b041-41d1-d860-bd3cf56533ac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "pnF_Wc8pol2c",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw_T-7w7pYEg"
      },
      "source": [
        "Initial setup above"
      ],
      "id": "Iw_T-7w7pYEg"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmLwD54EoDIf"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "id": "mmLwD54EoDIf",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJfWNvM3qssC"
      },
      "source": [
        "from extra_keras_datasets import svhn\n",
        "import tensorflow as tf\n",
        "import keras"
      ],
      "id": "SJfWNvM3qssC",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHCS1ZcToDUi"
      },
      "source": [
        "#!pip install extra-keras-datasets"
      ],
      "id": "VHCS1ZcToDUi",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "7fec15c7-def2-45b9-8456-881564d76398"
      },
      "source": [
        "### 1. Load the Street View House Numbers (SVHN) dataset\n",
        "\n",
        "-   Download the SVHN database and load the train and test datasets!\n",
        "    There are multiple ways to do this. The easiest one is probably to install\n",
        "    and use the `extra-keras-datasets` Python package. You need to use the\n",
        "    standard/normal SVHN dataset only and NOT the one titled as `extra`!\n",
        "    (Of course, if you have enough RAM and VRAM, you can work with that one\n",
        "    too, if you want...)\n",
        "-   Preprocess the downloaded data if needed to be able to use it for training\n",
        "    and testing!\n",
        "-   Normalize the pixel values into the interval of [0,1]!\n",
        "-   How many and what classes do we have in the dataset? How many train and test\n",
        "    examples do we have?\n",
        "-   What are the dimensions of the images?\n",
        "-   Show some images randomly from the dataset!\n",
        "-   Make one-hot encoding for the labels!"
      ],
      "id": "7fec15c7-def2-45b9-8456-881564d76398"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfzDTPoI4JUs"
      },
      "source": [
        "Download and check the data"
      ],
      "id": "YfzDTPoI4JUs"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hU65pMRMp6LL",
        "outputId": "fdaa642b-ea05-40b0-b8b4-ddbaa4750335"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = svhn.load_data(type='normal')"
      ],
      "id": "hU65pMRMp6LL",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Loading dataset = svhn\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from http://ufldl.stanford.edu/housenumbers/train_32x32.mat\n",
            "182042624/182040794 [==============================] - 11s 0us/step\n",
            "182050816/182040794 [==============================] - 11s 0us/step\n",
            "Downloading data from http://ufldl.stanford.edu/housenumbers/test_32x32.mat\n",
            "64282624/64275384 [==============================] - 5s 0us/step\n",
            "64290816/64275384 [==============================] - 5s 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Please cite the following paper when using or referencing this Extra Keras Dataset:\n",
            "WARNING:root:Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng Reading Digits in Natural Images with Unsupervised Feature Learning NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011. Retrieved from http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf\n",
            "WARNING:root:Noncommercial use is allowed only: see the SVHN website for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbX6kC9Zp6Pl",
        "outputId": "591cdf50-6563-4a6e-d81f-fb74d5e47590"
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "id": "sbX6kC9Zp6Pl",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((73257, 32, 32, 3), (73257,), (26032, 32, 32, 3), (26032,))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jifOdnFl1mtg",
        "outputId": "2a60d0fb-bc9e-4f56-f816-f184c34e1a98"
      },
      "source": [
        "np.isnan(X_train).sum(),np.isnan(y_train).sum(),np.isnan(X_test).sum(),np.isnan(y_test).sum()"
      ],
      "id": "jifOdnFl1mtg",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0, 0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZqYp3uN4QB4"
      },
      "source": [
        "Need to make the pixels between 0 and 1."
      ],
      "id": "vZqYp3uN4QB4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS_lphk3uTOH",
        "outputId": "2986c190-3bbb-4bdc-9804-21fb9d32ce9a"
      },
      "source": [
        "X_train.min(), X_train.max()"
      ],
      "id": "xS_lphk3uTOH",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 255)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBKbxfivObj6"
      },
      "source": [
        "# from https://www.tutorialspoint.com/keras/keras_convolution_neural_network.htm\n",
        "from keras import backend as K\n",
        "img_rows, img_cols = 32, 32\n",
        "\n",
        "if K.image_data_format() == 'channels_first': \n",
        "   x_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols) \n",
        "   x_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols) \n",
        "   input_shape = (1, img_rows, img_cols) \n",
        "else: \n",
        "   x_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 3) \n",
        "   x_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 3) \n",
        "   input_shape = (img_rows, img_cols, 3) \n",
        "   \n",
        "x_train = x_train.astype('float32') \n",
        "x_test = x_test.astype('float32') \n",
        "x_train /= 255 \n",
        "x_test /= 255"
      ],
      "id": "MBKbxfivObj6",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFY_3Kk6tohG"
      },
      "source": [
        "#x_train = X_train.reshape(73257, 32*32*3)/255\n",
        "#x_test = X_test.reshape(26032, 32*32*3)/255"
      ],
      "id": "QFY_3Kk6tohG",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzNCCTfl378r"
      },
      "source": [
        "Shapes of the sets in order: input train, output train, input test, output test"
      ],
      "id": "TzNCCTfl378r"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sho0hO7tooq",
        "outputId": "0f5a0383-eecc-4a21-9f4e-24e95f1bf3e6"
      },
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "id": "4Sho0hO7tooq",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((73257, 32, 32, 3), (73257,), (26032, 32, 32, 3), (26032,))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "e_7atDAAtosh",
        "outputId": "c2f0d632-4709-4ef2-9910-77acb5c0e629"
      },
      "source": [
        "plt.imshow(x_train[19].reshape(32,32,3))\n",
        "plt.title('This is number %i'%y_train[19])"
      ],
      "id": "e_7atDAAtosh",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'This is number 8')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "id": "LAcGDzKv77ou",
        "outputId": "9a802d21-9e6b-4d80-fc32-6d5744a7d2ab"
      },
      "source": [
        "plt.imshow(x_train[727].reshape(32,32,3))\n",
        "plt.title('This is number %i'%y_train[727])"
      ],
      "id": "LAcGDzKv77ou",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'This is number 8')"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3Obmw8zwFPk",
        "outputId": "1fd27502-2ce1-474a-b29c-a07dd4fddebd"
      },
      "source": [
        "print(\"Unique classes: \", len(np.unique(y_test)))"
      ],
      "id": "D3Obmw8zwFPk",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique classes:  10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jlctWWu4PxfK",
        "outputId": "9c593b98-68cc-425c-ea8a-84b2a4d54b30"
      },
      "source": [
        "np.unique(y_test-1)"
      ],
      "id": "jlctWWu4PxfK",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N19PD_Tt6vGo"
      },
      "source": [
        "One hot encoding, seems OK!"
      ],
      "id": "N19PD_Tt6vGo"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbMOUkKM1lC5",
        "outputId": "1d6b364a-63d8-433a-9cc0-48de79033afc"
      },
      "source": [
        "y_train_oh = tf.keras.utils.to_categorical(y_train-1, 10)\n",
        "y_test_oh = tf.keras.utils.to_categorical(y_test-1, 10)\n",
        "print(y_train_oh[:5], y_train[:5])"
      ],
      "id": "kbMOUkKM1lC5",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]] [1 9 2 3 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d72057e3-894b-44e1-bef8-5a7ef8b811e2"
      },
      "source": [
        "### 2. Create a convolutional neural network for the SVHN dataset\n",
        "\n",
        "-   Train the following network on the training set and generate\n",
        "    prediction for the test images:\n",
        "    ```\n",
        "          > conv2D, 16 kernels, kernel size = (3,3), valid padding, relu actvation\n",
        "          > conv2D, 16 kernels, kernel size = (3,3), valid padding, relu actvation\n",
        "          > maxpooling kernel size = (2,2)\n",
        "          > conv2D, 32 kernels, kernel size = (3,3), valid padding, relu actvation\n",
        "          > conv2D, 32 kernels, kernel size = (3,3), valid padding, relu actvation\n",
        "          > maxpooling pool size = (2,2) strides = (2,2)\n",
        "          > flatten\n",
        "          > dense, 10 neurons, softmax activation\n",
        "    ```\n",
        "    -   Use Adam optimizer with default parameters\n",
        "    -   Use categorical crossentropy as loss function\n",
        "    -   Compile the model\n",
        "    -   Print out a summary of the model\n",
        "    -   Train the CNN on the training data for 25 epochs with batch size\n",
        "        of 64\n",
        "    -   Use the test data as validation data\n",
        "\n",
        "-   Calculate the categorical cross-entropy loss and the accuracy!\n",
        "    **<font color='green'>[HINT]:</font>** you should get at least $\\approx$ 80-90%\n",
        "    accuracy.\n",
        "-   Plot the training and the validation loss and accuracy on the same plot!\n",
        "    Do we experience overfitting?\n",
        "-   Show the confusion matrix of the predictions!"
      ],
      "id": "d72057e3-894b-44e1-bef8-5a7ef8b811e2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWf0esNH-qe_"
      },
      "source": [
        "Aided with understanding the exercise: https://www.tutorialspoint.com/keras/keras_convolution_neural_network.htm"
      ],
      "id": "sWf0esNH-qe_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66EGqaB-AqWS"
      },
      "source": [
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten \n",
        "from keras.layers import Conv2D, MaxPooling2D "
      ],
      "id": "66EGqaB-AqWS",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVDmlMY-8RsM",
        "outputId": "35488b53-ca3f-4299-d8b4-b867cd6b8d37"
      },
      "source": [
        "x_train.shape"
      ],
      "id": "FVDmlMY-8RsM",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(73257, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNKAfbdq8R4k"
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "model.add(Conv2D(16,\n",
        "                 kernel_size=(3,3),\n",
        "                 padding='valid',\n",
        "                 activation='relu'))\n",
        "model.add(Conv2D(16, kernel_size=(3,3), padding='valid', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Conv2D(32, kernel_size=(3,3), padding='valid', activation='relu'))\n",
        "model.add(Conv2D(32, kernel_size=(3,3), padding='valid', activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))\n"
      ],
      "id": "kNKAfbdq8R4k",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "czq-lDaH8R-w"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy','AUC'])"
      ],
      "id": "czq-lDaH8R-w",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8ewibmvH3Bu",
        "outputId": "1f30f328-b4d6-49be-e6fc-d017604f53d2"
      },
      "source": [
        "history = model.fit(x=x_train, y=y_train_oh,\n",
        "                    batch_size=64, epochs=25,\n",
        "                    validation_data=(x_test, y_test_oh))"
      ],
      "id": "E8ewibmvH3Bu",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1145/1145 [==============================] - 25s 13ms/step - loss: 0.9209 - accuracy: 0.7096 - auc: 0.9494 - val_loss: 0.6195 - val_accuracy: 0.8294 - val_auc: 0.9738\n",
            "Epoch 2/25\n",
            "1145/1145 [==============================] - 14s 12ms/step - loss: 0.5020 - accuracy: 0.8555 - auc: 0.9825 - val_loss: 0.5095 - val_accuracy: 0.8580 - val_auc: 0.9815\n",
            "Epoch 3/25\n",
            "1145/1145 [==============================] - 13s 11ms/step - loss: 0.4409 - accuracy: 0.8729 - auc: 0.9858 - val_loss: 0.4944 - val_accuracy: 0.8576 - val_auc: 0.9828\n",
            "Epoch 4/25\n",
            "1145/1145 [==============================] - 14s 12ms/step - loss: 0.4050 - accuracy: 0.8822 - auc: 0.9877 - val_loss: 0.4515 - val_accuracy: 0.8728 - val_auc: 0.9854\n",
            "Epoch 5/25\n",
            "1145/1145 [==============================] - 14s 12ms/step - loss: 0.3822 - accuracy: 0.8894 - auc: 0.9888 - val_loss: 0.4516 - val_accuracy: 0.8706 - val_auc: 0.9847\n",
            "Epoch 6/25\n",
            "1145/1145 [==============================] - 14s 12ms/step - loss: 0.3637 - accuracy: 0.8940 - auc: 0.9897 - val_loss: 0.4514 - val_accuracy: 0.8715 - val_auc: 0.9846\n",
            "Epoch 7/25\n",
            "1145/1145 [==============================] - 14s 12ms/step - loss: 0.3481 - accuracy: 0.8982 - auc: 0.9905 - val_loss: 0.4397 - val_accuracy: 0.8712 - val_auc: 0.9855\n",
            "Epoch 8/25\n",
            "1145/1145 [==============================] - 14s 12ms/step - loss: 0.3363 - accuracy: 0.9019 - auc: 0.9909 - val_loss: 0.4152 - val_accuracy: 0.8796 - val_auc: 0.9868\n",
            "Epoch 9/25\n",
            "1145/1145 [==============================] - 15s 13ms/step - loss: 0.3245 - accuracy: 0.9051 - auc: 0.9915 - val_loss: 0.4103 - val_accuracy: 0.8853 - val_auc: 0.9861\n",
            "Epoch 10/25\n",
            "1145/1145 [==============================] - 14s 13ms/step - loss: 0.3126 - accuracy: 0.9095 - auc: 0.9919 - val_loss: 0.4191 - val_accuracy: 0.8821 - val_auc: 0.9859\n",
            "Epoch 11/25\n",
            "1145/1145 [==============================] - 14s 12ms/step - loss: 0.2996 - accuracy: 0.9130 - auc: 0.9924 - val_loss: 0.4040 - val_accuracy: 0.8868 - val_auc: 0.9869\n",
            "Epoch 12/25\n",
            "1145/1145 [==============================] - 14s 12ms/step - loss: 0.2940 - accuracy: 0.9140 - auc: 0.9927 - val_loss: 0.4006 - val_accuracy: 0.8877 - val_auc: 0.9871\n",
            "Epoch 13/25\n",
            "1145/1145 [==============================] - 15s 13ms/step - loss: 0.2862 - accuracy: 0.9159 - auc: 0.9930 - val_loss: 0.3938 - val_accuracy: 0.8883 - val_auc: 0.9872\n",
            "Epoch 14/25\n",
            "1145/1145 [==============================] - 14s 12ms/step - loss: 0.2776 - accuracy: 0.9183 - auc: 0.9933 - val_loss: 0.3989 - val_accuracy: 0.8876 - val_auc: 0.9868\n",
            "Epoch 15/25\n",
            "1145/1145 [==============================] - 14s 12ms/step - loss: 0.2716 - accuracy: 0.9211 - auc: 0.9935 - val_loss: 0.4011 - val_accuracy: 0.8861 - val_auc: 0.9867\n",
            "Epoch 16/25\n",
            "1145/1145 [==============================] - 14s 12ms/step - loss: 0.2653 - accuracy: 0.9221 - auc: 0.9937 - val_loss: 0.3891 - val_accuracy: 0.8914 - val_auc: 0.9876\n",
            "Epoch 17/25\n",
            "1145/1145 [==============================] - 14s 12ms/step - loss: 0.2604 - accuracy: 0.9244 - auc: 0.9939 - val_loss: 0.4060 - val_accuracy: 0.8908 - val_auc: 0.9863\n",
            "Epoch 18/25\n",
            "1145/1145 [==============================] - 14s 12ms/step - loss: 0.2542 - accuracy: 0.9248 - auc: 0.9942 - val_loss: 0.4111 - val_accuracy: 0.8888 - val_auc: 0.9861\n",
            "Epoch 19/25\n",
            "1145/1145 [==============================] - 14s 12ms/step - loss: 0.2506 - accuracy: 0.9263 - auc: 0.9942 - val_loss: 0.3940 - val_accuracy: 0.8919 - val_auc: 0.9867\n",
            "Epoch 20/25\n",
            "1145/1145 [==============================] - 14s 12ms/step - loss: 0.2473 - accuracy: 0.9273 - auc: 0.9942 - val_loss: 0.4033 - val_accuracy: 0.8882 - val_auc: 0.9867\n",
            "Epoch 21/25\n",
            "1145/1145 [==============================] - 15s 13ms/step - loss: 0.2414 - accuracy: 0.9297 - auc: 0.9945 - val_loss: 0.4042 - val_accuracy: 0.8867 - val_auc: 0.9867\n",
            "Epoch 22/25\n",
            "1145/1145 [==============================] - 14s 12ms/step - loss: 0.2380 - accuracy: 0.9302 - auc: 0.9946 - val_loss: 0.4218 - val_accuracy: 0.8838 - val_auc: 0.9855\n",
            "Epoch 23/25\n",
            "1145/1145 [==============================] - 14s 12ms/step - loss: 0.2346 - accuracy: 0.9313 - auc: 0.9947 - val_loss: 0.4017 - val_accuracy: 0.8943 - val_auc: 0.9862\n",
            "Epoch 24/25\n",
            "1145/1145 [==============================] - 15s 13ms/step - loss: 0.2317 - accuracy: 0.9314 - auc: 0.9949 - val_loss: 0.4248 - val_accuracy: 0.8821 - val_auc: 0.9855\n",
            "Epoch 25/25\n",
            "1145/1145 [==============================] - 15s 13ms/step - loss: 0.2275 - accuracy: 0.9332 - auc: 0.9949 - val_loss: 0.4203 - val_accuracy: 0.8869 - val_auc: 0.9856\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "bd6b8f6a-83a7-4fba-bfae-7fe501d934a9"
      },
      "source": [
        "### 3. Load the Sload Digital Sky Survey (SDSS) Dataset\n",
        "\n",
        "You can download the dataset from Kaggle via\n",
        "[this link](https://www.kaggle.com/masterdesky/multiband-photoz-sdss-dr16).\n",
        "\n",
        "-   Download the images from Kaggle (~10'000 images total) \n",
        "-   Preprocess the images similarly to the SVHN dataset if needed! (Normalize\n",
        "    pixel values to [0,1], etc.)\n",
        "-   What are the dimensions of the images?\n",
        "-   Show 15 images randomly from the dataset!\n",
        "-   Create a train-test-validation split using `train_test_split` from `sklearn`\n",
        "    where the test size is $0.33$ and the validation size is $0.2$\n",
        "    -   Set a random seed\n",
        "    -   Print the number of images in each of these sets after you've created\n",
        "        them"
      ],
      "id": "bd6b8f6a-83a7-4fba-bfae-7fe501d934a9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "d3aa9ad0-06e9-4ce3-81d3-29b35e1cd6ff"
      },
      "source": [
        "### 4. Create a convolutional neural network for the SDSS dataset\n",
        "\n",
        "-   Train the following network on the training set and generate\n",
        "    prediction for the test images:\n",
        "    ```\n",
        "          > conv2D, 32 kernels, kernel size = (3,3), same padding\n",
        "          > batch normalization\n",
        "          > relu actvation\n",
        "          > conv2D, 32 kernels, kernel size = (3,3), same padding\n",
        "          > batch normalization\n",
        "          > relu actvation\n",
        "          > maxpooling pool size = (2,2), strides = (2,2)\n",
        "          \n",
        "          > conv2D, 64 kernels, kernel size = (3,3), same padding\n",
        "          > batch normalization\n",
        "          > relu actvation\n",
        "          > conv2D, 64 kernels, kernel size = (1,1), same padding\n",
        "          > batch normalization\n",
        "          > relu actvation\n",
        "          > conv2D, 64 kernels, kernel size = (3,3), same padding\n",
        "          > batch normalization\n",
        "          > relu actvation\n",
        "          > maxpooling pool size = (2,2), strides = (2,2)\n",
        "          \n",
        "          > global pooling\n",
        "          > dense, 1 neuron, no activation\n",
        "    ```\n",
        "\n",
        "    -   Use Adam optimizer with default parameters\n",
        "    -   Use mean squared error as loss function\n",
        "    -   Compile the model\n",
        "    -   Print out a summary of the model\n",
        "    -   Use the created validation set as validation during the training\n",
        "    -   Train the CNN on the training data for 25 epochs with batch size\n",
        "        of 64\n",
        "\n",
        "-   Calculate and print out the final accuracy using the R2 score!"
      ],
      "id": "d3aa9ad0-06e9-4ce3-81d3-29b35e1cd6ff"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc00f33e-fcb8-45e8-a27f-3378cb40523e"
      },
      "source": [
        "### 5. Evaluate performance\n",
        "\n",
        "-   Plot the training and the validation loss on the same plot!\n",
        "-   Show the predicted values vs the actual labels on a plot!\n",
        "-   Where does the model make mistakes? Try to plot the images corresponding to\n",
        "    some outlier values!"
      ],
      "id": "bc00f33e-fcb8-45e8-a27f-3378cb40523e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5904d4c7-00c4-404f-a683-cee4dd6cccdb"
      },
      "source": [
        "### 6. Train an other CNN\n",
        "\n",
        "-   The previous architecture can be further improved.\n",
        "-   Come up with an architecture that can achieve more than 80-85% accuracy on \n",
        "    the test set if the accuracy metric is the R2 score!\n",
        "    -   You can use any tool for this task.\n",
        "    -   Remember that there are different losses and optimizers, early stopping,\n",
        "        regularization, etc. that can be useful for you. You can find more about \n",
        "        these eg. in the\n",
        "        [tensorflow/keras documentation](https://www.tensorflow.org/api_docs/python/tf/all_symbols).\n",
        "    -   Don't forget that you can add more layers to the model and train for\n",
        "        more epochs too... :)\n",
        "-   Print out the summary of this model!\n",
        "-   Plot the loss curves for this model too!"
      ],
      "id": "5904d4c7-00c4-404f-a683-cee4dd6cccdb"
    }
  ]
}