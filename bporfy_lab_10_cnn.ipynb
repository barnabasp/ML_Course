{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "name": "bporfy_lab_10_cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/barnabasp/ML_Course/blob/main/bporfy_lab_10_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "8b7e51d8-f81e-4c5f-8a48-7159ead65e99"
      },
      "source": [
        "# 10. Convolutional neural networks\n",
        "\n",
        "In this assignment you'll use a photo-Z dataset acquired from the observations of the SDSS telescope located in New Mexico. The goal is to predict redshifts from multiband images of galaxies. As a warmup you'll work with the SVHN dataset.\n",
        "\n",
        "**<font color='red'>[WARN]:</font> For this assignment you'll need significantly more computational power compared to previous assignments! If you don't have a CUDA-capable GPU with >4Gb VRAM and >8Gb RAM, then you're advised to work on Google Colab!**"
      ],
      "id": "8b7e51d8-f81e-4c5f-8a48-7159ead65e99"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-yT-15voDBB"
      },
      "source": [
        "#!unzip /content/drive/MyDrive/Colab\\ Notebooks/10/archive.zip"
      ],
      "id": "e-yT-15voDBB",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnF_Wc8pol2c",
        "outputId": "291e1e68-b732-4b48-b412-32dbebfa29d3"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "pnF_Wc8pol2c",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw_T-7w7pYEg"
      },
      "source": [
        "Initial setup above"
      ],
      "id": "Iw_T-7w7pYEg"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmLwD54EoDIf"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "id": "mmLwD54EoDIf",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJfWNvM3qssC"
      },
      "source": [
        "from extra_keras_datasets import svhn\n",
        "import tensorflow as tf\n",
        "import keras"
      ],
      "id": "SJfWNvM3qssC",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHCS1ZcToDUi",
        "outputId": "9cfc0de2-323a-4c56-db44-58d6e8f28395"
      },
      "source": [
        "!pip install extra-keras-datasets"
      ],
      "id": "VHCS1ZcToDUi",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting extra-keras-datasets\n",
            "  Downloading extra_keras_datasets-1.2.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from extra-keras-datasets) (1.0.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from extra-keras-datasets) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from extra-keras-datasets) (1.4.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from extra-keras-datasets) (1.1.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->extra-keras-datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->extra-keras-datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->extra-keras-datasets) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->extra-keras-datasets) (3.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->extra-keras-datasets) (1.1.0)\n",
            "Installing collected packages: extra-keras-datasets\n",
            "Successfully installed extra-keras-datasets-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "7fec15c7-def2-45b9-8456-881564d76398"
      },
      "source": [
        "### 1. Load the Street View House Numbers (SVHN) dataset\n",
        "\n",
        "-   Download the SVHN database and load the train and test datasets!\n",
        "    There are multiple ways to do this. The easiest one is probably to install\n",
        "    and use the `extra-keras-datasets` Python package. You need to use the\n",
        "    standard/normal SVHN dataset only and NOT the one titled as `extra`!\n",
        "    (Of course, if you have enough RAM and VRAM, you can work with that one\n",
        "    too, if you want...)\n",
        "-   Preprocess the downloaded data if needed to be able to use it for training\n",
        "    and testing!\n",
        "-   Normalize the pixel values into the interval of [0,1]!\n",
        "-   How many and what classes do we have in the dataset? How many train and test\n",
        "    examples do we have?\n",
        "-   What are the dimensions of the images?\n",
        "-   Show some images randomly from the dataset!\n",
        "-   Make one-hot encoding for the labels!"
      ],
      "id": "7fec15c7-def2-45b9-8456-881564d76398"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfzDTPoI4JUs"
      },
      "source": [
        "Download and check the data"
      ],
      "id": "YfzDTPoI4JUs"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hU65pMRMp6LL",
        "outputId": "dd98f45c-5cd0-4902-a0ed-090e797a7a0a"
      },
      "source": [
        "(X_train, y_train), (X_test, y_test) = svhn.load_data(type='normal')"
      ],
      "id": "hU65pMRMp6LL",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:Loading dataset = svhn\n",
            "WARNING:root:Please cite the following paper when using or referencing this Extra Keras Dataset:\n",
            "WARNING:root:Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng Reading Digits in Natural Images with Unsupervised Feature Learning NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011. Retrieved from http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf\n",
            "WARNING:root:Noncommercial use is allowed only: see the SVHN website for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbX6kC9Zp6Pl",
        "outputId": "34321bd9-4368-4edd-8a3d-7dede89ab185"
      },
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "id": "sbX6kC9Zp6Pl",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((73257, 32, 32, 3), (73257,), (26032, 32, 32, 3), (26032,))"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jifOdnFl1mtg",
        "outputId": "69c4c31b-dae2-4b0b-e159-541a2230185f"
      },
      "source": [
        "np.isnan(X_train).sum(),np.isnan(y_train).sum(),np.isnan(X_test).sum(),np.isnan(y_test).sum()"
      ],
      "id": "jifOdnFl1mtg",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 0, 0, 0)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZqYp3uN4QB4"
      },
      "source": [
        "Need to make the pixels between 0 and 1."
      ],
      "id": "vZqYp3uN4QB4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS_lphk3uTOH",
        "outputId": "4b909631-53ab-439d-9dcc-a6bd64240e44"
      },
      "source": [
        "X_train.min(), X_train.max()"
      ],
      "id": "xS_lphk3uTOH",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, 255)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFY_3Kk6tohG"
      },
      "source": [
        "x_train = X_train.reshape(73257, 32*32, 3)/255\n",
        "x_test = X_test.reshape(26032, 32*32,3)/255"
      ],
      "id": "QFY_3Kk6tohG",
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzNCCTfl378r"
      },
      "source": [
        "Shapes of the sets in order: input train, output train, input test, output test"
      ],
      "id": "TzNCCTfl378r"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Sho0hO7tooq",
        "outputId": "3f25b77e-93fb-45ef-ca46-abc64529844e"
      },
      "source": [
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "id": "4Sho0hO7tooq",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((73257, 1024, 3), (73257,), (26032, 1024, 3), (26032,))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "e_7atDAAtosh",
        "outputId": "f977eeaf-4a87-411d-865e-520aff3cf6d1"
      },
      "source": [
        "plt.imshow(x_train[19].reshape(32,32,3))"
      ],
      "id": "e_7atDAAtosh",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8aff7ad090>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3Obmw8zwFPk",
        "outputId": "b803638b-ad52-4e4d-ef74-3eadb103e210"
      },
      "source": [
        "print(\"Unique classes: \", len(np.unique(y_test)))"
      ],
      "id": "D3Obmw8zwFPk",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique classes:  10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N19PD_Tt6vGo"
      },
      "source": [
        "One hot encoding, seems OK!"
      ],
      "id": "N19PD_Tt6vGo"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbMOUkKM1lC5",
        "outputId": "69c8da09-802b-4dd2-b22e-29c0ddcf9138"
      },
      "source": [
        "y_train_oh = tf.keras.utils.to_categorical(y_train)\n",
        "y_test_oh = tf.keras.utils.to_categorical(y_test)\n",
        "print(y_train_oh[:5], y_train[:5])"
      ],
      "id": "kbMOUkKM1lC5",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]] [1 9 2 3 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d72057e3-894b-44e1-bef8-5a7ef8b811e2"
      },
      "source": [
        "### 2. Create a convolutional neural network for the SVHN dataset\n",
        "\n",
        "-   Train the following network on the training set and generate\n",
        "    prediction for the test images:\n",
        "    ```\n",
        "          > conv2D, 16 kernels, kernel size = (3,3), valid padding, relu actvation\n",
        "          > conv2D, 16 kernels, kernel size = (3,3), valid padding, relu actvation\n",
        "          > maxpooling kernel size = (2,2)\n",
        "          > conv2D, 32 kernels, kernel size = (3,3), valid padding, relu actvation\n",
        "          > conv2D, 32 kernels, kernel size = (3,3), valid padding, relu actvation\n",
        "          > maxpooling pool size = (2,2) strides = (2,2)\n",
        "          > flatten\n",
        "          > dense, 10 neurons, softmax activation\n",
        "    ```\n",
        "    -   Use Adam optimizer with default parameters\n",
        "    -   Use categorical crossentropy as loss function\n",
        "    -   Compile the model\n",
        "    -   Print out a summary of the model\n",
        "    -   Train the CNN on the training data for 25 epochs with batch size\n",
        "        of 64\n",
        "    -   Use the test data as validation data\n",
        "\n",
        "-   Calculate the categorical cross-entropy loss and the accuracy!\n",
        "    **<font color='green'>[HINT]:</font>** you should get at least $\\approx$ 80-90%\n",
        "    accuracy.\n",
        "-   Plot the training and the validation loss and accuracy on the same plot!\n",
        "    Do we experience overfitting?\n",
        "-   Show the confusion matrix of the predictions!"
      ],
      "id": "d72057e3-894b-44e1-bef8-5a7ef8b811e2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "bd6b8f6a-83a7-4fba-bfae-7fe501d934a9"
      },
      "source": [
        "### 3. Load the Sload Digital Sky Survey (SDSS) Dataset\n",
        "\n",
        "You can download the dataset from Kaggle via\n",
        "[this link](https://www.kaggle.com/masterdesky/multiband-photoz-sdss-dr16).\n",
        "\n",
        "-   Download the images from Kaggle (~10'000 images total) \n",
        "-   Preprocess the images similarly to the SVHN dataset if needed! (Normalize\n",
        "    pixel values to [0,1], etc.)\n",
        "-   What are the dimensions of the images?\n",
        "-   Show 15 images randomly from the dataset!\n",
        "-   Create a train-test-validation split using `train_test_split` from `sklearn`\n",
        "    where the test size is $0.33$ and the validation size is $0.2$\n",
        "    -   Set a random seed\n",
        "    -   Print the number of images in each of these sets after you've created\n",
        "        them"
      ],
      "id": "bd6b8f6a-83a7-4fba-bfae-7fe501d934a9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "d3aa9ad0-06e9-4ce3-81d3-29b35e1cd6ff"
      },
      "source": [
        "### 4. Create a convolutional neural network for the SDSS dataset\n",
        "\n",
        "-   Train the following network on the training set and generate\n",
        "    prediction for the test images:\n",
        "    ```\n",
        "          > conv2D, 32 kernels, kernel size = (3,3), same padding\n",
        "          > batch normalization\n",
        "          > relu actvation\n",
        "          > conv2D, 32 kernels, kernel size = (3,3), same padding\n",
        "          > batch normalization\n",
        "          > relu actvation\n",
        "          > maxpooling pool size = (2,2), strides = (2,2)\n",
        "          \n",
        "          > conv2D, 64 kernels, kernel size = (3,3), same padding\n",
        "          > batch normalization\n",
        "          > relu actvation\n",
        "          > conv2D, 64 kernels, kernel size = (1,1), same padding\n",
        "          > batch normalization\n",
        "          > relu actvation\n",
        "          > conv2D, 64 kernels, kernel size = (3,3), same padding\n",
        "          > batch normalization\n",
        "          > relu actvation\n",
        "          > maxpooling pool size = (2,2), strides = (2,2)\n",
        "          \n",
        "          > global pooling\n",
        "          > dense, 1 neuron, no activation\n",
        "    ```\n",
        "\n",
        "    -   Use Adam optimizer with default parameters\n",
        "    -   Use mean squared error as loss function\n",
        "    -   Compile the model\n",
        "    -   Print out a summary of the model\n",
        "    -   Use the created validation set as validation during the training\n",
        "    -   Train the CNN on the training data for 25 epochs with batch size\n",
        "        of 64\n",
        "\n",
        "-   Calculate and print out the final accuracy using the R2 score!"
      ],
      "id": "d3aa9ad0-06e9-4ce3-81d3-29b35e1cd6ff"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc00f33e-fcb8-45e8-a27f-3378cb40523e"
      },
      "source": [
        "### 5. Evaluate performance\n",
        "\n",
        "-   Plot the training and the validation loss on the same plot!\n",
        "-   Show the predicted values vs the actual labels on a plot!\n",
        "-   Where does the model make mistakes? Try to plot the images corresponding to\n",
        "    some outlier values!"
      ],
      "id": "bc00f33e-fcb8-45e8-a27f-3378cb40523e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5904d4c7-00c4-404f-a683-cee4dd6cccdb"
      },
      "source": [
        "### 6. Train an other CNN\n",
        "\n",
        "-   The previous architecture can be further improved.\n",
        "-   Come up with an architecture that can achieve more than 80-85% accuracy on \n",
        "    the test set if the accuracy metric is the R2 score!\n",
        "    -   You can use any tool for this task.\n",
        "    -   Remember that there are different losses and optimizers, early stopping,\n",
        "        regularization, etc. that can be useful for you. You can find more about \n",
        "        these eg. in the\n",
        "        [tensorflow/keras documentation](https://www.tensorflow.org/api_docs/python/tf/all_symbols).\n",
        "    -   Don't forget that you can add more layers to the model and train for\n",
        "        more epochs too... :)\n",
        "-   Print out the summary of this model!\n",
        "-   Plot the loss curves for this model too!"
      ],
      "id": "5904d4c7-00c4-404f-a683-cee4dd6cccdb"
    }
  ]
}